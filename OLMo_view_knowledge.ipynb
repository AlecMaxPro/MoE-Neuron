{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064c063f-978a-4e5e-adf0-f14d40ef9376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "import torch\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "from collections import Counter\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "LAYER_NUM = 32\n",
    "HEAD_NUM = 32\n",
    "HEAD_DIM = 128\n",
    "HIDDEN_DIM = HEAD_NUM * HEAD_DIM # 4096 \n",
    "# n=1\n",
    "TYPE=\"OLMo\"\n",
    "torch.set_default_device(\"cuda:4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d85f679-911d-47fb-bb64-871d3303419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_output(model_output):\n",
    "    all_pos_layer_input = []\n",
    "    all_pos_attn_output = []\n",
    "    all_pos_residual_output = []\n",
    "    all_pos_ffn_output = []\n",
    "    all_pos_layer_output = []\n",
    "    all_last_attn_subvalues = []\n",
    "    all_pos_coefficient_scores = []\n",
    "    all_attn_scores = []\n",
    "    single_attn = []\n",
    "    for layer_i in range(LAYER_NUM):\n",
    "        cur_layer_input = model_output[layer_i][0]\n",
    "        cur_attn_output = model_output[layer_i][1]\n",
    "        cur_residual_output = model_output[layer_i][2]\n",
    "        cur_ffn_output = model_output[layer_i][3]\n",
    "        cur_layer_output = model_output[layer_i][4]\n",
    "        cur_last_attn_subvalues = model_output[layer_i][5]\n",
    "        cur_coefficient_scores = model_output[layer_i][6]\n",
    "        cur_attn_weights = model_output[layer_i][7]\n",
    "        cur_single_attn = model_output[layer_i][8]\n",
    "        all_pos_layer_input.append(cur_layer_input[0].tolist())\n",
    "        all_pos_attn_output.append(cur_attn_output[0].tolist())\n",
    "        all_pos_residual_output.append(cur_residual_output[0].tolist())\n",
    "        all_pos_ffn_output.append(cur_ffn_output[0].tolist())\n",
    "        all_pos_layer_output.append(cur_layer_output[0].tolist())\n",
    "        all_last_attn_subvalues.append(cur_last_attn_subvalues[0].tolist())\n",
    "        all_pos_coefficient_scores.append(cur_coefficient_scores[0].tolist())\n",
    "        all_attn_scores.append(cur_attn_weights)\n",
    "        single_attn.append(cur_single_attn.tolist())\n",
    "    return all_pos_layer_input, all_pos_attn_output, all_pos_residual_output, all_pos_ffn_output, \\\n",
    "           all_pos_layer_output, all_last_attn_subvalues, all_pos_coefficient_scores, all_attn_scores, single_attn\n",
    "def get_fc2_params(model, layer_num):\n",
    "    return model.model.layers[layer_num].mlp.down_proj.weight.data\n",
    "def get_bsvalues(vector, model, final_var):\n",
    "    vector = vector * torch.rsqrt(final_var + 1e-6)\n",
    "    vector_rmsn = vector * model.model.norm.weight.data\n",
    "    vector_bsvalues = model.lm_head(vector_rmsn).data\n",
    "    return vector_bsvalues\n",
    "def get_prob(vector):\n",
    "    prob = torch.nn.Softmax(-1)(vector)\n",
    "    return prob\n",
    "def transfer_l(l):\n",
    "    new_x, new_y = [], []\n",
    "    for x in l:\n",
    "        new_x.append(x[0])\n",
    "        new_y.append(x[1])\n",
    "    return new_x, new_y\n",
    "def plt_bar(x, y, yname=\"log increase\"):\n",
    "    x_major_locator=MultipleLocator(1)\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    ax=plt.gca()\n",
    "    ax.xaxis.set_major_locator(x_major_locator)\n",
    "    plt_x = [a/2 for a in x]\n",
    "    plt.xlim(-0.5, plt_x[-1]+0.49)\n",
    "    x_attn, y_attn, x_ffn, y_ffn = [], [], [], []\n",
    "    for i in range(len(x)):\n",
    "        if i%2 == 0:\n",
    "            x_attn.append(x[i]/2)\n",
    "            y_attn.append(y[i])\n",
    "        else:\n",
    "            x_ffn.append(x[i]/2)\n",
    "            y_ffn.append(y[i])\n",
    "    plt.bar(x_attn, y_attn, color=\"darksalmon\", label=\"attention layers\")\n",
    "    plt.bar(x_ffn, y_ffn, color=\"lightseagreen\", label=\"FFN layers\")\n",
    "    plt.xlabel(\"layer\")\n",
    "    plt.ylabel(yname)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "def plt_heatmap(data):\n",
    "    xLabel = range(len(data[0]))\n",
    "    yLabel = range(len(data))\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xticks(range(len(xLabel)))\n",
    "    ax.set_xticklabels(xLabel)\n",
    "    ax.set_yticks(range(len(yLabel)))\n",
    "    ax.set_yticklabels(yLabel)\n",
    "    im = ax.imshow(data, cmap=plt.cm.hot_r)\n",
    "    plt.title(\"attn head log increase heatmap\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ac4ed2-a2b2-4367-8606-c4003c13c063",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelname = \"your own model dir\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelname)\n",
    "model = AutoModelForCausalLM.from_pretrained(modelname)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f659766",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "parameters = {\"test_sentence\": \"The capital of France is\", \"n\":1}\n",
    "test_sentence = parameters[\"test_sentence\"]\n",
    "# model_file = parameters.get(\"model_file\", \"default_model\")\n",
    "n = parameters[\"n\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14f9ec5-8ba2-499a-aa3c-dbb409937d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_tokens = tokenizer.encode(test_sentence)\n",
    "tokens = [tokenizer.decode(x) for x in indexed_tokens]\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "with torch.no_grad():\n",
    "    outputs = model(tokens_tensor)\n",
    "    predictions = outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8712449",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_top10 = torch.argsort(predictions[0][-1], descending=True)[:10]\n",
    "predicted_text = [tokenizer.decode(x) for x in predicted_top10]\n",
    "print(test_sentence, \"=>\", predicted_text)\n",
    "all_pos_layer_input, all_pos_attn_output, all_pos_residual_output, all_pos_ffn_output, all_pos_layer_output, \\\n",
    "all_last_attn_subvalues, all_pos_coefficient_scores, all_attn_scores, single_attn = transfer_output(outputs[1])\n",
    "final_var = torch.tensor(all_pos_layer_output[-1][-1]).pow(2).mean(-1, keepdim=True)\n",
    "pos_len = len(tokens)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613acef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_index = predicted_top10[0].item()\n",
    "print(predict_index, tokenizer.decode(predict_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315ecfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attn_outputs = {}\n",
    "\n",
    "\n",
    "for layer in range(LAYER_NUM):\n",
    "    attn_outputs[f\"layer_{layer}\"] = single_attn[layer][-1]\n",
    "\n",
    "# print(attn_outputs)\n",
    "\n",
    "# eg. /OLMo/{TYPE}/{model_file}'\n",
    "base_dir = f'Output_Dir'\n",
    "\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "target_dir = os.path.join(base_dir, str(n))\n",
    "if not os.path.exists(target_dir):\n",
    "    os.makedirs(target_dir)\n",
    "\n",
    "file_path = os.path.join(target_dir, 'attn_outputs.json')\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(attn_outputs, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae6b5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attn_scores_data = {}\n",
    "\n",
    "\n",
    "for layer in range(LAYER_NUM):\n",
    "    attn_scores_data[f\"layer_{layer}\"] = {}\n",
    "    for head in range(HEAD_NUM):\n",
    "        attn_scores_data[f\"layer_{layer}\"][f\"head_{head}\"] = all_attn_scores[layer][-1][head].tolist()\n",
    "\n",
    "# print(attn_scores_data)\n",
    "\n",
    "# eg. /OLMo/{TYPE}/{model_file}'\n",
    "base_dir = f'Output_Dir'\n",
    "\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "target_dir = os.path.join(base_dir, str(n))\n",
    "if not os.path.exists(target_dir):\n",
    "    os.makedirs(target_dir)\n",
    "\n",
    "file_path = os.path.join(target_dir, 'attn_scores.json')\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(attn_scores_data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7c59f7-94e6-424a-9bff-6d948d58c759",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#layer-level increase (value layers)\n",
    "all_attn_log_increase = []\n",
    "for layer_i in range(LAYER_NUM):\n",
    "    cur_attn_vector = torch.tensor(all_pos_attn_output[layer_i][-1])\n",
    "    cur_layer_input = torch.tensor(all_pos_layer_input[layer_i][-1])\n",
    "    origin_prob_log = torch.log(get_prob(get_bsvalues(cur_layer_input, model, final_var))[predict_index])\n",
    "    cur_attn_vector_plus = cur_attn_vector + cur_layer_input\n",
    "    cur_attn_vector_bsvalues = get_bsvalues(cur_attn_vector_plus, model, final_var)\n",
    "    cur_attn_vector_probs = get_prob(cur_attn_vector_bsvalues)\n",
    "    cur_attn_vector_probs = cur_attn_vector_probs[predict_index]\n",
    "    cur_attn_vector_probs_log = torch.log(cur_attn_vector_probs)\n",
    "    cur_attn_vector_probs_log_increase = cur_attn_vector_probs_log - origin_prob_log\n",
    "    all_attn_log_increase.append(cur_attn_vector_probs_log_increase.item())\n",
    "all_ffn_log_increase = []\n",
    "for layer_i in range(LAYER_NUM):\n",
    "    cur_ffn_vector = torch.tensor(all_pos_ffn_output[layer_i][-1])\n",
    "    cur_residual = torch.tensor(all_pos_residual_output[layer_i][-1])\n",
    "    origin_prob_log = torch.log(get_prob(get_bsvalues(cur_residual, model, final_var))[predict_index])\n",
    "    cur_ffn_vector_plus = cur_ffn_vector + cur_residual\n",
    "    cur_ffn_vector_bsvalues = get_bsvalues(cur_ffn_vector_plus, model, final_var)\n",
    "    cur_ffn_vector_probs = get_prob(cur_ffn_vector_bsvalues)\n",
    "    cur_ffn_vector_probs = cur_ffn_vector_probs[predict_index]\n",
    "    cur_ffn_vector_probs_log = torch.log(cur_ffn_vector_probs)\n",
    "    cur_ffn_vector_probs_log_increase = cur_ffn_vector_probs_log - origin_prob_log\n",
    "    all_ffn_log_increase.append(cur_ffn_vector_probs_log_increase.tolist())\n",
    "attn_list, ffn_list = [], []\n",
    "for layer_i in range(LAYER_NUM):\n",
    "    attn_list.append([str(layer_i), all_attn_log_increase[layer_i]])\n",
    "    ffn_list.append([str(layer_i), all_ffn_log_increase[layer_i]])\n",
    "attn_list_sort = sorted(attn_list, key=lambda x: x[-1])[::-1]#[:10]\n",
    "ffn_list_sort = sorted(ffn_list, key=lambda x: x[-1])[::-1]#[:10]\n",
    "attn_increase_compute, ffn_increase_compute = [], []\n",
    "for indx, increase in attn_list_sort:\n",
    "    attn_increase_compute.append((indx, round(increase, 3)))\n",
    "for indx, increase in ffn_list_sort:\n",
    "    ffn_increase_compute.append((indx, round(increase, 3)))\n",
    "print(\"attn sum: \", sum([x[1] for x in attn_increase_compute]), \n",
    "      \"ffn sum: \", sum([x[1] for x in ffn_increase_compute]))\n",
    "print(\"attn: \", attn_increase_compute)\n",
    "print(\"ffn: \", ffn_increase_compute)\n",
    "all_increases_draw = []\n",
    "for i in range(len(attn_list)):\n",
    "    all_increases_draw.append(attn_list[i][1])\n",
    "    all_increases_draw.append(ffn_list[i][1])    \n",
    "plt_bar(range(len(all_increases_draw)), all_increases_draw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db553c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = {\n",
    "    \"attn_list\": attn_list,\n",
    "    \"ffn_list\": ffn_list\n",
    "}\n",
    "\n",
    "# eg. /OLMo/{TYPE}/{model_file}'\n",
    "base_dir = f'Output_Dir'\n",
    "\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "target_dir = os.path.join(base_dir, str(n))\n",
    "if not os.path.exists(target_dir):\n",
    "    os.makedirs(target_dir)\n",
    "file_path = os.path.join(target_dir, f'layer_level_increase.json')\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(output_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ab589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#head-level increase (value heads)\n",
    "all_head_increase = []\n",
    "for test_layer in range(LAYER_NUM):\n",
    "    cur_layer_input = torch.tensor(all_pos_layer_input[test_layer])\n",
    "    cur_v_heads = torch.tensor(all_last_attn_subvalues[test_layer])\n",
    "    cur_attn_o_split = model.model.layers[test_layer].self_attn.o_proj.weight.data.T.contiguous().view(HEAD_NUM, HEAD_DIM, -1)\n",
    "    cur_attn_subvalues_headrecompute = torch.bmm(cur_v_heads, cur_attn_o_split).permute(1, 0, 2)\n",
    "    cur_attn_subvalues_head_sum = torch.sum(cur_attn_subvalues_headrecompute, 0)\n",
    "    cur_layer_input_last = cur_layer_input[-1]\n",
    "    origin_prob = torch.log(get_prob(get_bsvalues(cur_layer_input_last, model, final_var))[predict_index])\n",
    "    cur_attn_subvalues_head_plus = cur_attn_subvalues_head_sum + cur_layer_input_last\n",
    "    cur_attn_plus_probs = torch.log(get_prob(get_bsvalues(\n",
    "            cur_attn_subvalues_head_plus, model, final_var))[:, predict_index])\n",
    "    cur_attn_plus_probs_increase = cur_attn_plus_probs - origin_prob\n",
    "    for i in range(len(cur_attn_plus_probs_increase)):\n",
    "        all_head_increase.append([str(test_layer)+\"_\"+str(i), round(cur_attn_plus_probs_increase[i].item(), 4)])\n",
    "\n",
    "all_head_increase_sort = sorted(all_head_increase, key=lambda x:x[-1])[::-1]\n",
    "print(all_head_increase_sort[:30])\n",
    "all_head_increase_list = [x[1] for x in all_head_increase]\n",
    "all_head_increase_list_split = torch.tensor(all_head_increase_list).view((LAYER_NUM, HEAD_NUM)).permute((1,0)).tolist()\n",
    "plt_heatmap(all_head_increase_list_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171ab494",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_head_increase)\n",
    "output_data = {\n",
    "    \"all_head_increase\": all_head_increase\n",
    "}\n",
    "\n",
    "# eg. /OLMo/{TYPE}/{model_file}'\n",
    "base_dir = f'Output_Dir'\n",
    "\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "\n",
    "target_dir = os.path.join(base_dir, str(n))\n",
    "if not os.path.exists(target_dir):\n",
    "    os.makedirs(target_dir)\n",
    "file_path = os.path.join(target_dir, f'head_level_increase.json')\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(output_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccc33ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attn neuron increase (value attention neuron)\n",
    "cur_file_attn_neuron_list = []\n",
    "for test_layer in range(LAYER_NUM):\n",
    "    \n",
    "    target_device = 'cuda:5'\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    cur_layer_input = torch.tensor(all_pos_layer_input[test_layer]).to(target_device)\n",
    "    cur_v_heads_recompute = torch.tensor(all_last_attn_subvalues[test_layer]).permute(1, 0, 2).to(target_device)\n",
    "    cur_attn_o_split = model.model.layers[test_layer].self_attn.o_proj.weight.data.T.view(HEAD_NUM, HEAD_DIM, -1).to(target_device)\n",
    "    \n",
    "    cur_attn_o_recompute = cur_attn_o_split * cur_v_heads_recompute.unsqueeze(-1)\n",
    "    cur_layer_input_last = cur_layer_input[-1]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        temp_input = cur_layer_input_last.to('cuda:4')\n",
    "        origin_prob = torch.log(get_prob(get_bsvalues(temp_input, model, final_var))[predict_index])\n",
    "        del temp_input\n",
    "    \n",
    "    cur_attn_o_head_plus = cur_attn_o_recompute + cur_layer_input_last\n",
    "    \n",
    "    batch_size = 32  \n",
    "    num_positions = cur_attn_o_head_plus.size(0)\n",
    "    \n",
    "    cur_attn_plus_probs_increase_list = []\n",
    "    \n",
    "    for batch_start in range(0, num_positions, batch_size):\n",
    "        batch_end = min(batch_start + batch_size, num_positions)\n",
    "        batch_data = cur_attn_o_head_plus[batch_start:batch_end]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            temp_batch = batch_data.to('cuda:4')\n",
    "            batch_probs = torch.log(get_prob(get_bsvalues(temp_batch, model, final_var))[:, :, :, predict_index])\n",
    "            batch_increase = batch_probs - origin_prob\n",
    "            cur_attn_plus_probs_increase_list.append(batch_increase.cpu())\n",
    "            del temp_batch, batch_probs, batch_increase\n",
    "    \n",
    "\n",
    "    cur_attn_plus_probs_increase = torch.cat(cur_attn_plus_probs_increase_list, dim=0)\n",
    "    \n",
    "    for pos_index in range(cur_attn_plus_probs_increase.size(0)):\n",
    "        for head_index in range(cur_attn_plus_probs_increase.size(1)):\n",
    "            for attn_neuron_index in range(cur_attn_plus_probs_increase.size(2)):\n",
    "                cur_file_attn_neuron_list.append((str(test_layer)+\"_\"+str(head_index)+\"_\"+str(\n",
    "                    attn_neuron_index)+\"_\"+str(pos_index), \n",
    "                    cur_attn_plus_probs_increase[pos_index][head_index][attn_neuron_index].item()))\n",
    "\n",
    "    del cur_layer_input, cur_v_heads_recompute, cur_attn_o_split, cur_attn_o_recompute\n",
    "    del cur_layer_input_last, cur_attn_o_head_plus, cur_attn_plus_probs_increase_list, cur_attn_plus_probs_increase\n",
    "    \n",
    "    if test_layer % 5 == 0:  \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "cur_file_attn_neuron_list_sort = sorted(cur_file_attn_neuron_list, key=lambda x: x[-1])[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7ea97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_neuron_data = [\n",
    "    {\n",
    "        \"neuron\": item[0],\n",
    "        \"increase\": item[1]\n",
    "    }\n",
    "    for item in cur_file_attn_neuron_list_sort\n",
    "]\n",
    "    \n",
    "# eg. /OLMo/{TYPE}/{model_file}'\n",
    "base_dir = f'Output_Dir'\n",
    "\n",
    "\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "target_dir = os.path.join(base_dir, str(n))\n",
    "if not os.path.exists(target_dir):\n",
    "    os.makedirs(target_dir)\n",
    "file_path = os.path.join(target_dir, f'attn_neuron_increase.json')\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(attn_neuron_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b534d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the number of value attention neurons in different layers\n",
    "attn_value_neurons = [x[0] for x in cur_file_attn_neuron_list_sort[:300]]\n",
    "attn_layer_count_value = [int(x.split(\"_\")[0]) for x in list(attn_value_neurons)]\n",
    "attn_layer_count_value = Counter(attn_layer_count_value)\n",
    "attn_layer_count_value = sorted(zip(attn_layer_count_value.keys(), attn_layer_count_value.values()))\n",
    "qwenmoe_attn_value_x, qwenmoe_attn_value_y = transfer_l(attn_layer_count_value)\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.plot(qwenmoe_attn_value_x, qwenmoe_attn_value_y, \"ro-\", label=\"OLMo attn value neurons\")\n",
    "plt.xlabel(\"layer\", fontsize=10)\n",
    "plt.ylabel(\"count\", fontsize=10)\n",
    "plt.legend(fontsize=10, loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52682ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FFN neuron increase (value FFN neuron)\n",
    "all_ffn_subvalues = []\n",
    "for layer_i in range(LAYER_NUM):\n",
    "    coefficient_scores = torch.tensor(all_pos_coefficient_scores[layer_i][-1])\n",
    "    fc2_vectors = get_fc2_params(model, layer_i)\n",
    "    ffn_subvalues = (coefficient_scores * fc2_vectors).T\n",
    "    all_ffn_subvalues.append(ffn_subvalues)\n",
    "ffn_subvalue_list = []\n",
    "for layer_i in range(LAYER_NUM):\n",
    "    cur_ffn_subvalues = all_ffn_subvalues[layer_i]\n",
    "    cur_residual = torch.tensor(all_pos_residual_output[layer_i][-1])\n",
    "    origin_prob_log = torch.log(get_prob(get_bsvalues(cur_residual, model, final_var))[predict_index])\n",
    "    cur_ffn_subvalues_plus = cur_ffn_subvalues + cur_residual\n",
    "    cur_ffn_subvalues_bsvalues = get_bsvalues(cur_ffn_subvalues_plus, model, final_var)\n",
    "    cur_ffn_subvalues_probs = get_prob(cur_ffn_subvalues_bsvalues)\n",
    "    cur_ffn_subvalues_probs = cur_ffn_subvalues_probs[:, predict_index]\n",
    "    cur_ffn_subvalues_probs_log = torch.log(cur_ffn_subvalues_probs)\n",
    "    cur_ffn_subvalues_probs_log_increase = cur_ffn_subvalues_probs_log - origin_prob_log\n",
    "    for index, ffn_increase in enumerate(cur_ffn_subvalues_probs_log_increase):\n",
    "        ffn_subvalue_list.append([str(layer_i)+\"_\"+str(index), ffn_increase.item()])\n",
    "ffn_subvalue_list_sort = sorted(ffn_subvalue_list, key=lambda x: x[-1])[::-1]\n",
    "for x in ffn_subvalue_list_sort[:10]:\n",
    "    print(x[0], round(x[1], 4))\n",
    "    layer = int(x[0].split(\"_\")[0])\n",
    "    neuron = int(x[0].split(\"_\")[1])\n",
    "    cur_vector = get_fc2_params(model, layer).T[neuron]\n",
    "    cur_vector_bsvalue = get_bsvalues(cur_vector, model, final_var)\n",
    "    cur_vector_bsvalue_sort = torch.argsort(cur_vector_bsvalue, descending=True)\n",
    "    print(\"top10: \", [tokenizer.decode(a) for a in cur_vector_bsvalue_sort[:10]])\n",
    "    print(\"last10: \", [tokenizer.decode(a) for a in cur_vector_bsvalue_sort[-10:].tolist()[::-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75538c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ffn_subvalue_list_sort\n",
    "ffn_neuron_data = [\n",
    "    {\n",
    "        \"layer\": int(item[0].split('_')[0]),\n",
    "        \"neuron\": int(item[0].split('_')[1]),\n",
    "        \"increase\": item[1]\n",
    "    }\n",
    "    for item in data\n",
    "]\n",
    "\n",
    "# eg. /OLMo/{TYPE}/{model_file}'\n",
    "base_dir = f'Output_Dir'\n",
    "\n",
    "\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "\n",
    "target_dir = os.path.join(base_dir, str(n))\n",
    "if not os.path.exists(target_dir):\n",
    "    os.makedirs(target_dir)\n",
    "file_path = os.path.join(target_dir, f'FFN_neuron_increase.json')\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(ffn_neuron_data, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ff3a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the number of value FFN neurons in different layers\n",
    "FFN_value_neurons = [x[0] for x in ffn_subvalue_list_sort[:300]]\n",
    "FFN_layer_count_value = [int(x.split(\"_\")[0]) for x in list(FFN_value_neurons)]\n",
    "FFN_layer_count_value = Counter(FFN_layer_count_value)\n",
    "FFN_layer_count_value = sorted(zip(FFN_layer_count_value.keys(), FFN_layer_count_value.values()))\n",
    "gpt_FFN_value_x, gpt_FFN_value_y = transfer_l(FFN_layer_count_value)\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.plot(gpt_FFN_value_x, gpt_FFN_value_y, \"bo-\", label=\"OLMo FFN value neurons\")\n",
    "plt.xlabel(\"layer\", fontsize=10)\n",
    "plt.ylabel(\"count\", fontsize=10)\n",
    "plt.legend(fontsize=10, loc=\"upper right\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attribution",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
